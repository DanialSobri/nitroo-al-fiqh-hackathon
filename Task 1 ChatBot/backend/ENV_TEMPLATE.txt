# Copy this file to .env and configure your settings

# LLM Provider Selection
# Options: "openai", "ollama" (recommended), or "api_gateway" (deprecated)
LLM_PROVIDER=ollama

# OpenAI Configuration (if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
LLM_TEMPERATURE=0.7

# Ollama Configuration (if LLM_PROVIDER=ollama) - RECOMMENDED
OLLAMA_URL=https://v-wkp54x2qz-11434.tma01.com.my/
OLLAMA_MODEL=phi4:14b

# API Gateway Configuration (deprecated - use ollama instead)
# API_GATEWAY_TOKEN_URL=
# API_GATEWAY_CHAT_URL=
# API_GATEWAY_AUTH_HEADER=
# API_GATEWAY_COOKIE=
# API_GATEWAY_MODEL=phi4:14b

# Qdrant Configuration
# Use Qdrant server (recommended)
QDRANT_URL=http://localhost:6333
# Or use local file database (leave QDRANT_URL empty)
QDRANT_PATH=../Web-Scraper/qdrant_db

# RAG Configuration
MAX_RETRIEVAL_RESULTS=5
MIN_SIMILARITY_SCORE=0.5

# Advanced RAG Configuration (Context Window Optimization)
# Enable diversity filtering using MMR (Maximal Marginal Relevance)
ENABLE_DIVERSITY_FILTERING=True
DIVERSITY_THRESHOLD=0.7  # 0=diversity, 1=relevance (0.7=balanced)

# Multi-stage retrieval (retrieve more, then filter/re-rank)
INITIAL_RETRIEVAL_COUNT=20  # Retrieve more candidates initially
FINAL_RETRIEVAL_COUNT=5     # Final count after filtering

# Context management
MAX_CONTEXT_LENGTH=4000     # Maximum context size in characters (reduced for smaller payloads)
ENABLE_SMART_TRUNCATION=True  # Smart context prioritization
USE_COMPACT_PROMPT=True     # Use shorter, more compact prompt template (saves ~200 chars)

# Advanced features (disabled by default - requires additional setup)
ENABLE_RERANKING=False       # Cross-encoder re-ranking (requires model)
ENABLE_QUERY_EXPANSION=False # Generate query variations
ENABLE_CONTEXT_COMPRESSION=False # Summarize context before LLM
ENABLE_HYBRID_SEARCH=False  # Combine vector + keyword search

# Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Legacy LLM Configuration (for backward compatibility)
LLM_MODEL=phi4:14b
